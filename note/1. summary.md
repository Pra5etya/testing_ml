### 1. sklearn.datasets
Menyediakan dataset yang siap pakai seperti iris, wine, digits, serta alat untuk memuat dataset eksternal (CSV, JSON, dll.).

#### Komponen Penting:
- **load_iris()**, **fetch_openml()**

#### Contoh Kode:
```python
from sklearn.datasets import load_iris

# Memuat dataset Iris
iris = load_iris()
print(iris.data[:5])  # Menampilkan 5 baris pertama data
```

### 2. sklearn.model_selection
Modul ini berfungsi untuk pembagian data, validasi model, dan pemilihan model terbaik melalui cross-validation.

#### Komponen Penting:
- **train_test_split**: Memisahkan dataset menjadi set pelatihan dan pengujian.
- **cross_val_score**, **cross_val_predict**: Evaluasi model dengan cross-validation.
- **GridSearchCV**, **RandomizedSearchCV**: Tuning hyperparameter.

#### Contoh Kode:
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_wine

# Memuat dataset
wine = load_wine()
X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3, random_state=42)

# Melatih model
model = RandomForestClassifier()
model.fit(X_train, y_train)
print("Akurasi:", model.score(X_test, y_test))
```

### 3. sklearn.preprocessing
Menawarkan alat untuk praproses data sebelum diterapkan ke model.

#### Komponen Penting:
- **StandardScaler**, **MinMaxScaler**: Normalisasi fitur.
- **OneHotEncoder**, **LabelEncoder**: Encoding variabel kategorikal.
- **PolynomialFeatures**: Membuat fitur polinomial.

#### Contoh Kode:
```python
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import numpy as np

# Normalisasi data
scaler = StandardScaler()
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
scaled_data = scaler.fit_transform(data)
print(scaled_data)

# Encoding data kategorikal
encoder = OneHotEncoder()
categorical_data = np.array([['A'], ['B'], ['A']])
encoded_data = encoder.fit_transform(categorical_data).toarray()
print(encoded_data)
```

### 4. sklearn.impute
Modul untuk menangani data yang hilang (missing values).

#### Komponen Penting:
- **SimpleImputer**: Mengisi nilai yang hilang.
- **KNNImputer**: Menggunakan KNN.

#### Contoh Kode:
```python
from sklearn.impute import SimpleImputer
import numpy as np

# Mengisi nilai hilang
data = np.array([[1, 2, np.nan], [3, np.nan, 5], [np.nan, 6, 7]])
imputer = SimpleImputer(strategy='mean')
filled_data = imputer.fit_transform(data)
print(filled_data)
```

### 5. sklearn.pipeline
Memungkinkan Anda menggabungkan langkah praproses dan model dalam satu pipeline terstruktur.

#### Komponen Penting:
- **Pipeline**: Menggabungkan transformasi dan model.
- **FeatureUnion**: Menggabungkan beberapa transformasi secara paralel.

#### Contoh Kode:
```python
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris

# Membuat pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

# Melatih pipeline
iris = load_iris()
pipeline.fit(iris.data, iris.target)
print("Akurasi:", pipeline.score(iris.data, iris.target))
```

### 6. sklearn.compose
Digunakan untuk menggabungkan berbagai transformasi pada fitur yang berbeda.

#### Komponen Penting:
- **ColumnTransformer**: Menerapkan transformasi pada kolom yang berbeda.
- **TransformedTargetRegressor**: Transformasi pada target (label).

#### Contoh Kode:
```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import pandas as pd

# Data contoh
data = pd.DataFrame({
    'numerical': [1, 2, 3],
    'categorical': ['A', 'B', 'A']
})

# Transformasi kolom
transformer = ColumnTransformer([
    ('num', StandardScaler(), ['numerical']),
    ('cat', OneHotEncoder(), ['categorical'])
])
transformed_data = transformer.fit_transform(data)
print(transformed_data)
```

### 7. sklearn.decomposition
Alat untuk pengurangan dimensi (dimensionality reduction).

#### Komponen Penting:
- **PCA**: Principal Component Analysis.

#### Contoh Kode:
```python
from sklearn.decomposition import PCA
import numpy as np

# Data contoh
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(data)
print(reduced_data)
```

### 8. sklearn.ensemble
Berisi metode ensemble untuk meningkatkan performa model.

#### Komponen Penting:
- **RandomForestClassifier**, **GradientBoostingClassifier**

#### Contoh Kode:
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_digits

# Melatih model ensemble
digits = load_digits()
model = RandomForestClassifier()
model.fit(digits.data, digits.target)
print("Akurasi:", model.score(digits.data, digits.target))
```

### 9. sklearn.linear_model
Berisi berbagai algoritma regresi dan klasifikasi berbasis linear.

#### Komponen Penting:
- **LinearRegression**, **LogisticRegression**

#### Contoh Kode:
```python
from sklearn.linear_model import LinearRegression
import numpy as np

# Melatih model regresi linear
X = np.array([[1], [2], [3]])
y = np.array([2, 4, 6])
model = LinearRegression()
model.fit(X, y)
print("Koefisien:", model.coef_)
```

### 10. sklearn.metrics
Modul untuk evaluasi model machine learning.

#### Komponen Penting:
- **accuracy_score**, **mean_squared_error**

#### Contoh Kode:
```python
from sklearn.metrics import accuracy_score

# Evaluasi model
y_true = [0, 1, 1, 0]
y_pred = [0, 1, 0, 0]
print("Akurasi:", accuracy_score(y_true, y_pred))
```

### 11. sklearn.svm
Implementasi Support Vector Machines (SVM).

#### Komponen Penting:
- **SVC**, **SVR**

#### Contoh Kode:
```python
from sklearn.svm import SVC
from sklearn.datasets import load_iris

# Melatih model SVM
iris = load_iris()
model = SVC()
model.fit(iris.data, iris.target)
print("Akurasi:", model.score(iris.data, iris.target))
```

### 12. sklearn.neighbors
Modul yang menyediakan algoritma K-Nearest Neighbors (KNN).

#### Komponen Penting:
- **KNeighborsClassifier**, **KNeighborsRegressor**

#### Contoh Kode:
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris

# Melatih model KNN
iris = load_iris()
model = KNeighborsClassifier()
model.fit(iris.data, iris.target)
print("Akurasi:", model.score(iris.data, iris.target))
```

### 13. sklearn.tree
Berisi algoritma Decision Tree.

#### Komponen Penting:
- **DecisionTreeClassifier**, **DecisionTreeRegressor**

#### Contoh Kode:
```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris

# Melatih model pohon keputusan
iris = load_iris()
model = DecisionTreeClassifier()
model.fit(iris.data, iris.target)
print("Akurasi:", model.score(iris.data, iris.target))
```

### 14. sklearn.cluster
Alat untuk pengelompokan data (clustering).

#### Komponen Penting:
- **KMeans**, **DBSCAN**

#### Contoh Kode:
```python
from sklearn.cluster import KMeans
import numpy as np

# Melatih model clustering
data = np.array([[1, 2], [3, 4], [5, 6]])
model = KMeans(n_clusters=2)
model.fit(data)
print("Cluster Centers:", model.cluster_centers_)
```

### 15. sklearn.feature_selection
Modul untuk memilih fitur yang paling relevan.

#### Komponen Penting:
- **SelectKBest**, **RFE**

#### Contoh Kode:
```python
from sklearn.feature_selection import SelectKBest, chi2
import numpy as np

# Memilih fitur terbaik
X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
y = np.array([1, 0, 1])
selector = SelectKBest(score_func=chi2, k=2)
X_new = selector.fit_transform(X, y)
print(X_new)
```

### 16. sklearn.utils.validation
Alat untuk validasi input data dan parameter.

#### Komponen Penting:
- **check_X_y**, **check_array**

#### Contoh Kode:
```python
from sklearn.utils.validation import check_X_y
import numpy as np

# Validasi input
X = np.array([[1, 2], [3, 4]])
y = np.array([1, 0])
X_checked, y_checked = check_X_y(X, y)
print("Validasi Berhasil")
```