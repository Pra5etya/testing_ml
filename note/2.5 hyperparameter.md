# Pencarian Hyperparameter Terbaik untuk Berbagai Model Machine Learning

Dalam pencarian **hyperparameter terbaik**, ada beberapa metode pencarian yang bisa digunakan, seperti **GridSearchCV**, **RandomizedSearchCV**, **HalvingGridSearchCV**, dan **HalvingRandomSearchCV**. Pemilihan metode yang tepat bergantung pada jenis model, jumlah hyperparameter, dan ketersediaan sumber daya komputasi.

## 1. Linear Regression, Ridge, Lasso
- **Metode yang direkomendasikan**:  
  ✅ `GridSearchCV` → Karena jumlah hyperparameter sedikit dan training cepat.
- **Contoh parameter yang dicari**:
  ```python
  param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}
  grid_search = GridSearchCV(Ridge(), param_grid, cv=5)
  grid_search.fit(X_train, y_train)
  ```
- **Alasan menggunakan Grid Search**:
  - Model sederhana dengan sedikit hyperparameter.

## 2. Decision Tree
- **Metode yang direkomendasikan**:  
  ✅ `RandomizedSearchCV` → Karena jumlah hyperparameter banyak dan kompleks.  
  ✅ `HalvingGridSearchCV` → Jika ingin Grid Search tetapi lebih cepat.
- **Contoh parameter yang dicari**:
  ```python
  param_dist = {
      'max_depth': [5, 10, 20, None],
      'min_samples_split': [2, 5, 10],
      'min_samples_leaf': [1, 2, 5]
  }
  random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_dist, n_iter=10, cv=5, random_state=42)
  random_search.fit(X_train, y_train)
  ```
- **Alasan menggunakan Random Search**:
  - Banyak kombinasi hyperparameter, lebih efisien dibanding Grid Search.

## 3. Random Forest
- **Metode yang direkomendasikan**:  
  ✅ `RandomizedSearchCV` → Untuk pencarian cepat dan optimal.  
  ✅ `HalvingRandomSearchCV` → Untuk efisiensi tambahan pada dataset besar.
- **Contoh parameter yang dicari**:
  ```python
  param_dist = {
      'n_estimators': [50, 100, 200],
      'max_depth': [10, 20, None],
      'min_samples_split': [2, 5, 10],
      'max_features': ['sqrt', 'log2']
  }
  random_search = RandomizedSearchCV(RandomForestClassifier(), param_dist, n_iter=15, cv=5, random_state=42)
  random_search.fit(X_train, y_train)
  ```

## 4. Support Vector Machine (SVM)
- **Metode yang direkomendasikan**:  
  ✅ `GridSearchCV` → Jika dataset kecil & ingin hasil optimal.  
  ✅ `HalvingGridSearchCV` → Jika dataset besar & ingin efisiensi.
- **Contoh parameter yang dicari**:
  ```python
  param_grid = {
      'C': [0.1, 1, 10, 100],
      'kernel': ['linear', 'rbf'],
      'gamma': ['scale', 'auto']
  }
  grid_search = GridSearchCV(SVC(), param_grid, cv=5)
  grid_search.fit(X_train, y_train)
  ```

## 5. K-Nearest Neighbors (KNN)
- **Metode yang direkomendasikan**:  
  ✅ `GridSearchCV` → Jika jumlah tetangga (`k`) terbatas.  
  ✅ `RandomizedSearchCV` → Jika banyak kombinasi.

## 6. XGBoost / Gradient Boosting
- **Metode yang direkomendasikan**:  
  ✅ `RandomizedSearchCV` → Karena banyak hyperparameter yang bisa dicoba.  
  ✅ `Bayesian Optimization` → Jika ingin pencarian lebih efisien.
- **Contoh parameter yang dicari**:
  ```python
  param_dist = {
      'n_estimators': [100, 300, 500],
      'learning_rate': [0.01, 0.1, 0.2],
      'max_depth': [3, 6, 9],
      'subsample': [0.7, 0.8, 0.9]
  }
  random_search = RandomizedSearchCV(XGBClassifier(), param_dist, n_iter=20, cv=5, random_state=42)
  random_search.fit(X_train, y_train)
  ```

## 7. Neural Network (MLP, TensorFlow, PyTorch)
- **Metode yang direkomendasikan**:  
  ✅ `RandomizedSearchCV` → Jika menggunakan MLPClassifier dari Scikit-Learn.  
  ✅ `Bayesian Optimization` → Untuk deep learning (lebih efisien dari Random Search).
- **Contoh parameter yang dicari** (MLP Scikit-Learn):
  ```python
  param_dist = {
      'hidden_layer_sizes': [(50,), (100,), (50,50)],
      'activation': ['relu', 'tanh'],
      'solver': ['adam', 'sgd'],
      'alpha': [0.0001, 0.001, 0.01]
  }
  random_search = RandomizedSearchCV(MLPClassifier(), param_dist, n_iter=10, cv=5)
  random_search.fit(X_train, y_train)
  ```

## Kesimpulan: Metode Pencarian Hyperparameter Terbaik per Model
| Model | Metode Terbaik |
|--------|--------------|
| Linear Regression | GridSearchCV |
| Ridge, Lasso | GridSearchCV |
| Decision Tree | RandomizedSearchCV, HalvingGridSearchCV |
| Random Forest | RandomizedSearchCV, HalvingRandomSearchCV |
| SVM | GridSearchCV, HalvingGridSearchCV |
| KNN | GridSearchCV, RandomizedSearchCV |
| XGBoost | RandomizedSearchCV, Bayesian Optimization |
| Neural Network | RandomizedSearchCV, Bayesian Optimization |

## Metode lainnya
Bayesian Optimization

Menggunakan pendekatan probabilistik untuk menemukan kombinasi hyperparameter terbaik.

Implementasi populer:

scikit-optimize (BayesSearchCV)

hyperopt

optuna

6. Hyperband

Berdasarkan Successive Halving, tetapi lebih adaptif dalam alokasi sumber daya.

Implementasi di Optuna dan tune-sklearn.

7. Evolutionary Algorithms (Genetic Algorithm, Particle Swarm Optimization)

Menggunakan konsep seleksi alam untuk menemukan kombinasi terbaik.

Implementasi populer:

DEAP (Genetic Algorithm)

TPOT (Automated ML dengan Genetic Programming)

8. BOHB (Bayesian Optimization + Hyperband)

Kombinasi Bayesian Optimization dan Hyperband.

Dapat ditemukan dalam pustaka HpBandSter.