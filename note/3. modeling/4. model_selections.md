### Modul `sklearn.model_selection` pada Scikit-Learn

Modul `sklearn.model_selection` menyediakan berbagai fungsi untuk membagi data, melakukan validasi silang (cross-validation), mengevaluasi model, serta melakukan tuning parameter. Modul ini dirancang untuk mendukung berbagai jenis model seperti regresi, klasifikasi, clustering, dan data deret waktu.

---

## **1. Data Splitting**
### **Fungsi Utama**

#### **`train_test_split`**
Membagi dataset menjadi data training dan testing. Cocok untuk semua jenis model seperti:
- **Regresi**: Linear Regression, Ridge, Random Forest Regressor.
- **Klasifikasi**: Logistic Regression, Decision Tree, SVM.
- **Clustering**: Untuk evaluasi model clustering jika memiliki label ground truth.

**Contoh kode (Regresi - Linear Regression):**
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Data splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)
```

#### **`StratifiedShuffleSplit`**
Membagi dataset dengan menjaga distribusi label. Sangat berguna untuk klasifikasi dengan dataset tidak seimbang.

**Contoh kode (Klasifikasi - Logistic Regression):**
```python
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Splitting
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

# Model training
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

#### **`KFold`** dan **`StratifiedKFold`**
Digunakan untuk validasi silang dengan membagi data menjadi K lipatan:
- **`KFold`**: Untuk data umum.
- **`StratifiedKFold`**: Untuk klasifikasi dengan menjaga distribusi label di setiap lipatan.

**Contoh kode (Klasifikasi - Decision Tree):**
```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score

skf = StratifiedKFold(n_splits=5)
model = DecisionTreeClassifier(max_depth=3)
scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')
print("Mean Accuracy:", scores.mean())
```

#### **`TimeSeriesSplit`**
Digunakan untuk validasi silang pada data deret waktu (time series), dengan menjaga urutan kronologis.

**Contoh kode (Regresi - Ridge Regression):**
```python
from sklearn.model_selection import TimeSeriesSplit
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)
model = Ridge(alpha=1.0)

for train_index, test_index in tscv.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("MSE:", mean_squared_error(y_test, y_pred))
```

#### **`GroupKFold`**
Membagi data berdasarkan grup tertentu sehingga data dari satu grup tidak terbagi di lipatan yang berbeda.

**Contoh kode:**
```python
from sklearn.model_selection import GroupKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

groups = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]  # Grup data
gkf = GroupKFold(n_splits=3)

model = RandomForestClassifier()
for train_index, test_index in gkf.split(X, y, groups=groups):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, y_pred))
```

#### **`PredefinedSplit`**
Digunakan ketika pembagian data sudah ditentukan sebelumnya, misalnya berdasarkan indeks tertentu.

**Contoh kode:**
```python
from sklearn.model_selection import PredefinedSplit, cross_val_score
from sklearn.linear_model import LogisticRegression

test_fold = [-1 if i < 80 else 0 for i in range(100)]  # Data pertama untuk training, sisanya testing
ps = PredefinedSplit(test_fold)

model = LogisticRegression()
scores = cross_val_score(model, X, y, cv=ps)
print("Scores:", scores)
```

---

## **2. Cross-Validation dan Evaluasi Model**
### **Fungsi Utama**

#### **`cross_val_score`**
Menghitung skor evaluasi model untuk setiap lipatan dalam validasi silang.

**Contoh kode (Regresi - Ridge Regression):**
```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge

model = Ridge(alpha=1.0)
scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
print("Mean MSE:", -scores.mean())
```

#### **`validation_curve`**
Digunakan untuk mengevaluasi performa model dengan memvariasikan parameter tertentu.

**Contoh kode:**
```python
from sklearn.model_selection import validation_curve
from sklearn.svm import SVC
import numpy as np

param_range = np.logspace(-3, 3, 7)
train_scores, test_scores = validation_curve(SVC(), X, y, param_name="gamma", param_range=param_range, cv=5)

print("Train Scores:", train_scores.mean(axis=1))
print("Test Scores:", test_scores.mean(axis=1))
```

#### **`permutation_test_score`**
Mengukur signifikansi statistik model dengan membandingkan skor asli dengan data label yang telah diacak.

**Contoh kode:**
```python
from sklearn.model_selection import permutation_test_score
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
score, perm_scores, p_value = permutation_test_score(model, X, y, scoring="accuracy", cv=5, n_permutations=100)

print("Score:", score)
print("P-value:", p_value)
```

---

## **3. Hyperparameter Tuning**
### **Fungsi Utama**

#### **`GridSearchCV`**
Melakukan pencarian parameter terbaik melalui grid search dengan validasi silang.

**Contoh kode (Klasifikasi - SVM):**
```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')

grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
```

##### GridSearchCV Scoring Metriks pada Berbagai Model

Berikut adalah penjelasan tentang **scoring** dalam `GridSearchCV` dan penerapannya pada berbagai jenis model, baik untuk klasifikasi maupun regresi.

###### Klasifikasi
Untuk tugas klasifikasi, berikut adalah model yang sering digunakan beserta metrik yang relevan:

1. Model:
- **Logistic Regression** (`LogisticRegression`)
- **Support Vector Machine** (`SVC`)
- **Random Forest** (`RandomForestClassifier`)
- **Decision Tree** (`DecisionTreeClassifier`)
- **k-Nearest Neighbors** (`KNeighborsClassifier`)
- **Naive Bayes** (`GaussianNB`, `MultinomialNB`)
- **Gradient Boosting** (`GradientBoostingClassifier`)

2. Metrik `scoring` yang disarankan:
- **`accuracy`**: Cocok untuk dataset yang seimbang (jumlah data di setiap kelas serupa).
- **`precision`**: Berguna untuk kasus di mana kesalahan positif palsu (false positives) perlu diminimalkan, misalnya, dalam deteksi penipuan.
- **`recall`**: Digunakan ketika kesalahan negatif palsu (false negatives) lebih mahal, misalnya, dalam diagnosis penyakit.
- **`f1`**: Kombinasi presisi dan recall, berguna jika dataset tidak seimbang.
- **`roc_auc`**: Bagus untuk mengukur performa pada model klasifikasi biner, khususnya saat mempertimbangkan keseimbangan antara true positive rate dan false positive rate.

###### Regresi
Untuk tugas regresi, berikut adalah model yang cocok dengan metrik evaluasi regresi:

1. Model:
- **Linear Regression** (`LinearRegression`)
- **Ridge Regression** (`Ridge`)
- **Lasso Regression** (`Lasso`)
- **Support Vector Regressor** (`SVR`)
- **Random Forest Regressor** (`RandomForestRegressor`)
- **Decision Tree Regressor** (`DecisionTreeRegressor`)
- **Gradient Boosting Regressor** (`GradientBoostingRegressor`)

2. Metrik `scoring` yang disarankan:
- **`r2`**: Menilai seberapa baik model memprediksi data (nilai koefisien determinasi). Cocok digunakan untuk kebanyakan model regresi.
- **`neg_mean_squared_error`**: Mengukur kesalahan kuadrat rata-rata; negatif karena GridSearchCV memaksimalkan nilai.
- **`neg_mean_absolute_error`**: Mengukur kesalahan absolut rata-rata; lebih baik untuk mendeteksi outlier.
- **`neg_root_mean_squared_error`**: Akar dari *mean squared error*, digunakan saat ingin menilai kesalahan dalam skala yang sama dengan target.

###### Pertimbangan Model Spesifik
- **Support Vector Machines (SVM)**:
  - Klasifikasi: `accuracy`, `precision`, `recall`, `f1`, `roc_auc`
  - Regresi: `neg_mean_squared_error`, `r2`

- **Tree-based Models (Decision Tree, Random Forest, Gradient Boosting)**:
  - Klasifikasi: Semua metrik klasifikasi tergantung pada kebutuhan
  - Regresi: `r2`, `neg_mean_squared_error`, `neg_mean_absolute_error`
  
- **Logistic Regression**: Sering digunakan dengan `roc_auc`, `f1`, atau `accuracy` untuk klasifikasi.
- **K-Nearest Neighbors**: Cocok untuk `accuracy`, `f1`, atau `precision` tergantung pada data yang tidak seimbang atau skenario khusus.

###### Ringkasan Scoring:
- Untuk **klasifikasi dengan dataset seimbang**, pilih `accuracy`.
- Untuk **klasifikasi dengan dataset tidak seimbang**, pilih `f1`, `precision`, atau `recall` berdasarkan kebutuhan.
- Untuk **regresi**, pilih `r2` jika ingin memahami seberapa baik model menjelaskan variasi, atau gunakan kesalahan (MSE, MAE) untuk menilai performa lebih langsung.

Dengan pemilihan `scoring` yang tepat, Anda dapat mengoptimalkan model secara lebih efektif.




#### **`RandomizedSearchCV`**
Melakukan pencarian parameter secara acak.

**Contoh kode (Regresi - Random Forest Regressor):**
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {'n_estimators': randint(50, 200), 'max_depth': randint(5, 20)}
random_search = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error')

random_search.fit(X_train, y_train)
print("Best Parameters:", random_search.best_params_)
print("Best Score:", -random_search.best_score_)
```

#### **`HalvingGridSearchCV`**
Pendekatan efisien untuk pencarian parameter terbaik menggunakan successive halving.

**Contoh kode:**
```python
from sklearn.experimental import enable_halving_search_cv  # Perlu diaktifkan
from sklearn.model_selection import HalvingGridSearchCV
from sklearn.ensemble import RandomForestClassifier

param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}
halving_search = HalvingGridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy', factor=2)

halving_search.fit(X_train, y_train)
print("Best Params:", halving_search.best_params_)
print("Best Score:", halving_search.best_score_)
```

---

## **4. Analisis Kurva Pembelajaran**
### **`learning_curve`**
Membuat kurva pembelajaran untuk menganalisis performa model berdasarkan ukuran data.

**Contoh kode (Regresi - Random Forest):**
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt

train_sizes, train_scores, test_scores = learning_curve(RandomForestRegressor(), X, y, cv=5, scoring='neg_mean_squared_error')

train_scores_mean = -train_scores.mean(axis=1)
test_scores_mean = -test_scores.mean(axis=1)

# Plot learning curve
plt.plot(train_sizes, train_scores_mean, label='Training Error')
```

