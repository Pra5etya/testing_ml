{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh data pendapatan rumah tangga\n",
    "np.random.seed(42)\n",
    "low_income = np.random.exponential(scale=20000, size=1000)  # Mayoritas pendapatan rendah\n",
    "high_income = np.random.normal(loc=100000, scale=20000, size=50)  # Pendapatan tinggi (outlier)\n",
    "income_data = np.concatenate([low_income, high_income])\n",
    "\n",
    "income_data = pd.DataFrame(income_data)\n",
    "income_data.columns = ['income']\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(income_data, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribusi Pendapatan Rumah Tangga')\n",
    "plt.xlabel('Pendapatan')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "stat, p = shapiro(income_data)\n",
    "print(f\"Shapiro-Wilk Test: Statistic={stat}, p-value={p}\")\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Data berdistribusi normal\")\n",
    "else:\n",
    "    print(\"Data tidak berdistribusi normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi log\n",
    "income_data_log = np.log(income_data + 1)  # Tambahkan 1 untuk menghindari log(0)\n",
    "\n",
    "# Visualisasi distribusi setelah transformasi\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(income_data_log, bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribusi Pendapatan Setelah Transformasi Log')\n",
    "plt.xlabel('Log(Pendapatan)')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.show()\n",
    "\n",
    "# Uji normalitas lagi\n",
    "stat, p = shapiro(income_data_log)\n",
    "print(f\"Setelah Transformasi Log - Shapiro-Wilk Test: Statistic={stat}, p-value={p}\")\n",
    "if p > 0.05:\n",
    "    print(\"Data berdistribusi normal setelah transformasi\")\n",
    "else:\n",
    "    print(\"Data tetap tidak berdistribusi normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Clustering pada data transformasi\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(np.array(income_data_log).reshape(-1, 1))\n",
    "\n",
    "# Visualisasi hasil clustering\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(range(len(income_data_log)), income_data_log, c=clusters, cmap='viridis')\n",
    "plt.title('Clustering Pendapatan Rumah Tangga')\n",
    "plt.xlabel('Index Data')\n",
    "plt.ylabel('Log(Pendapatan)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan data berdasarkan cluster\n",
    "cluster_0 = income_data_log[np.array(clusters) == 0]\n",
    "cluster_1 = income_data_log[np.array(clusters) == 1]\n",
    "cluster_2 = income_data_log[np.array(clusters) == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Uji normalitas untuk setiap cluster\n",
    "for i, cluster_data in enumerate([cluster_0, cluster_1, cluster_2]):\n",
    "    stat, p = shapiro(cluster_data)\n",
    "    print(f\"Cluster {i}: Shapiro-Wilk Test Statistic={stat:.4f}, p-value={p:.4f}\")\n",
    "    if p > 0.05:\n",
    "        print(f\"Cluster {i} berdistribusi normal\")\n",
    "    else:\n",
    "        print(f\"Cluster {i} tidak berdistribusi normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualisasi distribusi per cluster\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, cluster_data in enumerate([cluster_0, cluster_1, cluster_2]):\n",
    "    sns.histplot(cluster_data, bins=30, kde=True, label=f'Cluster {i}', alpha=0.6)\n",
    "\n",
    "plt.title('Distribusi Log Pendapatan Per Cluster')\n",
    "plt.xlabel('Log(Pendapatan)')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset contoh\n",
    "data = {\n",
    "    \"Luas_Rumah\": [50, 80, 120, 200, 50, 100, 1200, 80, np.nan],\n",
    "    \"Jumlah_Kamar\": [2, 3, 4, 5, 2, 3, 6, 3, 3],\n",
    "    \"Lokasi\": [\"Pusat\", \"Pinggir\", \"Pinggir\", \"Pusat\", \"Pusat\", \"Pinggir\", \"Pinggir\", \"Pusat\", np.nan],\n",
    "    \"Usia_Bangunan\": [5, 10, 15, 20, 5, 10, 3, 8, 10],\n",
    "    \"Harga_Rumah\": [500, 700, 1000, 1500, 500, 800, 5000, 600, 700]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\POSCO-DX\\AppData\\Local\\Temp\\ipykernel_2988\\1747119776.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Luas_Rumah'].fillna(df['Luas_Rumah'].median(), inplace=True)\n",
      "C:\\Users\\POSCO-DX\\AppData\\Local\\Temp\\ipykernel_2988\\1747119776.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Lokasi'].fillna(df['Lokasi'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Menghapus duplikasi\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Menangani null values\n",
    "df['Luas_Rumah'].fillna(df['Luas_Rumah'].median(), inplace=True)\n",
    "df['Lokasi'].fillna(df['Lokasi'].mode()[0], inplace=True)\n",
    "\n",
    "# Mengatasi outliers dengan metode IQR\n",
    "Q1 = df['Luas_Rumah'].quantile(0.25)\n",
    "Q3 = df['Luas_Rumah'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df['Luas_Rumah'] >= lower_bound) & (df['Luas_Rumah'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi data\n",
    "X = df.drop(columns=['Harga_Rumah'])\n",
    "y = df['Harga_Rumah']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definisi fitur numerik dan kategori\n",
    "num_features = ['Luas_Rumah', 'Jumlah_Kamar', 'Usia_Bangunan']\n",
    "cat_features = ['Lokasi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1260 candidates, totalling 6300 fits\n",
      "Best Ridge Parameters: {'model__alpha': 0.01, 'model__fit_intercept': True, 'model__max_iter': 50000, 'model__random_state': None, 'model__solver': 'saga', 'model__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "# Hyperparameter Grid untuk GridSearchCV\n",
    "param_grid_ridge = {\n",
    "    'model__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__max_iter': [50000, 100000, 200000],\n",
    "    'model__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'model__random_state': [None, 42]\n",
    "}\n",
    "\n",
    "\n",
    "ridge_search = GridSearchCV(\n",
    "    estimator=ridge_pipeline,\n",
    "    param_grid=param_grid_ridge,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    error_score= 'raise',\n",
    "    verbose=1\n",
    ")\n",
    "ridge_search.fit(X_train, y_train)\n",
    "print(f\"Best Ridge Parameters: {ridge_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "Best Lasso Parameters: {'model__alpha': 1, 'model__fit_intercept': True, 'model__max_iter': 200000, 'model__random_state': None, 'model__selection': 'random', 'model__tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Lasso())\n",
    "])\n",
    "\n",
    "param_grid_lasso = {\n",
    "    'model__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__max_iter': [50000, 100000, 200000],\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'model__selection': ['cyclic', 'random'],\n",
    "    'model__random_state': [None, 42]\n",
    "}\n",
    "\n",
    "lasso_search = GridSearchCV(\n",
    "    estimator=lasso_pipeline,\n",
    "    param_grid=param_grid_lasso,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    error_score = 'raise', \n",
    "    verbose=1\n",
    ")\n",
    "lasso_search.fit(X_train, y_train)\n",
    "print(f\"Best Lasso Parameters: {lasso_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Best ElasticNet Parameters: {'model__alpha': 0.1, 'model__fit_intercept': True, 'model__l1_ratio': 0.9, 'model__max_iter': 50000, 'model__random_state': None, 'model__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "elasticnet_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid_elasticnet = {\n",
    "    'model__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__max_iter': [50000, 100000, 200000],\n",
    "    'model__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'model__random_state': [None, 42]\n",
    "}\n",
    "\n",
    "elasticnet_search = GridSearchCV(\n",
    "    estimator=elasticnet_pipeline,\n",
    "    param_grid=param_grid_elasticnet,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    error_score = 'raise', \n",
    "    verbose=1\n",
    ")\n",
    "elasticnet_search.fit(X_train, y_train)\n",
    "print(f\"Best ElasticNet Parameters: {elasticnet_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat pipeline dengan parameter terbaik\n",
    "ridge_best = ridge_search.best_estimator_\n",
    "lasso_best = lasso_search.best_estimator_\n",
    "elasticnet_best = elasticnet_search.best_estimator_\n",
    "\n",
    "# Linear Regression tetap default\n",
    "linear_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Voting Regressor dengan model terbaik\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('linear', linear_pipeline),\n",
    "        ('ridge', ridge_best),\n",
    "        ('lasso', lasso_best),\n",
    "        ('elasticnet', elasticnet_best)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (Voting Regressor): 97.12\n"
     ]
    }
   ],
   "source": [
    "# Training Voting Regressor\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi dan Evaluasi\n",
    "y_pred = voting_regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (Voting Regressor): {mae:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
