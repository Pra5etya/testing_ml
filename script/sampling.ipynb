{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mstats\n",
    "\n",
    "# data preparation\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# data modeling\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# data scoring\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# data tuning\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_round(x, pos): \n",
    "    if abs(x) >= 1e9: \n",
    "        return f'{x/1e9}B'\n",
    "    \n",
    "    elif abs(x) >= 1e6:\n",
    "        return f'{x/1e6}M'\n",
    "    \n",
    "    elif abs(x) >= 1e3:\n",
    "        return f'{x/1e3}K'\n",
    "    \n",
    "    else:\n",
    "        return f'{x}'\n",
    "    \n",
    "def val_round(x):\n",
    "    if abs(x) >= 1e9:\n",
    "        return f'{x/1e9:.2f} B'\n",
    "    \n",
    "    elif abs(x) >= 1e6:\n",
    "        return f'{x/1e6:.2f} M'\n",
    "    \n",
    "    elif abs(x) >= 1e3:\n",
    "        return f'{x/1e3:.2f} K'\n",
    "    \n",
    "    else:\n",
    "        return f'{x:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Custom Transformer untuk Menghapus Outlier ===\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "        self.bounds = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Hitung batas IQR untuk setiap fitur numerik\n",
    "        Q1 = X.quantile(0.25)\n",
    "        Q3 = X.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        self.bounds = {\"lower\": Q1 - self.factor * IQR, \n",
    "                       \"upper\": Q3 + self.factor * IQR,}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        mask = ~((X < self.bounds[\"lower\"]) | (X > self.bounds[\"upper\"])).any(axis=1)\n",
    "        return X[mask], y[mask] if y is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk konversi tipe data\n",
    "def convert_object_columns_to_numeric(df):\n",
    "    for col in df.select_dtypes(include = ['object']).columns:  \n",
    "        try:\n",
    "            # Cek apakah semua nilai bisa dikonversi ke float\n",
    "            df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "            \n",
    "            # Jika bisa, ubah ke int jika semua nilai adalah bilangan bulat\n",
    "            if all(df[col] % 1 == 0):  # Cek apakah semua nilai adalah bilangan bulat\n",
    "                df[col] = df[col].astype(int)\n",
    "\n",
    "        except ValueError:\n",
    "            pass  # Jika ada nilai non-angka, biarkan tetap object\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data train dan test\n",
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "test_df = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all column\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column\n",
    "train_df = train_df.drop('Id', axis = 1)\n",
    "\n",
    "# convert object if all numeric\n",
    "train_df = convert_object_columns_to_numeric(train_df)\n",
    "\n",
    "# check duplicate general data\n",
    "print(f'Total General Duplicated: {train_df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengelompokkan kolom yang memiliki nilai null ke dalam float_col dan str_col\n",
    "null_numeric = []\n",
    "null_obj = []\n",
    "\n",
    "# \n",
    "null_columns = train_df.columns[train_df.isnull().sum() > 0]\n",
    "\n",
    "for col in null_columns:\n",
    "    if train_df[col].dtype in ['int', 'float']:\n",
    "        null_numeric.append(col)\n",
    "        \n",
    "    elif train_df[col].dtype == 'object':\n",
    "        null_obj.append(col)\n",
    "\n",
    "print(\"Null Numeric:\", null_numeric)\n",
    "print(\"Null String:\", null_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mempertahankan original columns\n",
    "original = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline untuk numerik: imputasi nilai null dengan median\n",
    "numerical_pipeline = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy = \"mean\"))\n",
    "])\n",
    "\n",
    "# Pipeline untuk kategori: imputasi nilai null dengan modus\n",
    "categorical_pipeline = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy = \"most_frequent\"))\n",
    "])\n",
    "\n",
    "# ColumnTransformer untuk menggabungkan proses imputasi\n",
    "preprocessor_stage1 = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"num\", numerical_pipeline, null_numeric), \n",
    "        (\"cat\", categorical_pipeline, null_obj), \n",
    "    ], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data menggunakan fit_transform pada tahap 1\n",
    "train_df = preprocessor_stage1.fit_transform(train_df)\n",
    "\n",
    "# implement original column\n",
    "train_df = pd.DataFrame(train_df, columns = original)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan train_df adalah DataFrame\n",
    "if not isinstance(train_df, pd.DataFrame):\n",
    "    train_df = pd.DataFrame(train_df)\n",
    "\n",
    "# Menampilkan total null pada setiap kolom\n",
    "null_columns = train_df.isnull().sum()[train_df.isnull().sum() > 0]\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column\n",
    "test_df = test_df.drop('Id', axis = 1)\n",
    "\n",
    "# convert object if all numeric\n",
    "test_df = convert_object_columns_to_numeric(test_df)\n",
    "\n",
    "# check duplicate general data\n",
    "print(f'Total General Duplicated: {test_df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengelompokkan kolom yang memiliki nilai null ke dalam float_col dan str_col\n",
    "null_numeric = []\n",
    "null_obj = []\n",
    "\n",
    "# \n",
    "null_columns = test_df.columns[test_df.isnull().sum() > 0]\n",
    "\n",
    "for col in null_columns:\n",
    "    if test_df[col].dtype in ['int', 'float']:\n",
    "        null_numeric.append(col)\n",
    "        \n",
    "    elif test_df[col].dtype == 'object':\n",
    "        null_obj.append(col)\n",
    "\n",
    "print(\"Numeric Columns with Null Values:\", null_numeric)\n",
    "print(\"String Columns with Null Values:\", null_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mempertahankan original columns\n",
    "original = test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline untuk numerik: imputasi nilai null dengan median\n",
    "numerical_pipeline = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy = \"mean\"))\n",
    "])\n",
    "\n",
    "# Pipeline untuk kategori: imputasi nilai null dengan modus\n",
    "categorical_pipeline = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy = \"most_frequent\"))\n",
    "])\n",
    "\n",
    "# ColumnTransformer untuk menggabungkan proses imputasi\n",
    "preprocessor_stage1 = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"num\", numerical_pipeline, null_numeric),\n",
    "        (\"cat\", categorical_pipeline, null_obj)\n",
    "    ], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data menggunakan fit_transform pada tahap 1\n",
    "test_df = preprocessor_stage1.fit_transform(test_df)\n",
    "\n",
    "# implement original column\n",
    "test_df = pd.DataFrame(test_df, columns = original)\n",
    "\n",
    "# Konversi ulang tipe data jika perlu\n",
    "for col in null_numeric:\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan train_df adalah DataFrame\n",
    "if not isinstance(test_df, pd.DataFrame):\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "\n",
    "# Menampilkan total null pada setiap kolom\n",
    "null_columns = test_df.isnull().sum()[test_df.isnull().sum() > 0]\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar kolom untuk label encoding (kolom ordinal)\n",
    "encoding_set = {'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', \n",
    "                'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', \n",
    "                'FireplaceQu', 'GarageQual', 'GarageCond'}\n",
    "\n",
    "# Inisialisasi list untuk menyimpan kolom yang telah dikelompokkan\n",
    "train_ordinal_encoding_cols = []\n",
    "train_one_hot_encoding_cols = []\n",
    "train_numeric_cols = []\n",
    "\n",
    "# Mengelompokkan kolom berdasarkan tipe data\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype in ['int', 'float']:\n",
    "        train_numeric_cols.append(col)\n",
    "\n",
    "    elif train_df[col].dtype == 'object':\n",
    "        if col in encoding_set:\n",
    "            train_ordinal_encoding_cols.append(col)\n",
    "\n",
    "        else:\n",
    "            train_one_hot_encoding_cols.append(col)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"Label Encoding Columns:\", train_ordinal_encoding_cols)\n",
    "print(\"One-Hot Encoding Columns:\", train_one_hot_encoding_cols)\n",
    "print(\"Numeric Columns:\", train_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan kolom target dari data\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "# Memastikan kolom target ada di dalam DataFrame sebelum mencoba memisahkannya\n",
    "if target_col in train_df.columns:\n",
    "    X_train = train_df.drop(columns = [target_col])\n",
    "    y_train = train_df[target_col]\n",
    "\n",
    "else:\n",
    "    X_train = train_df  # Tidak memisahkan kolom target jika tidak ada\n",
    "    y_train = None  # Set y_train ke None jika kolom target tidak ditemukan\n",
    "\n",
    "if target_col in test_df.columns:\n",
    "    X_test = test_df.drop(columns = [target_col])\n",
    "    \n",
    "else:\n",
    "    X_test = test_df  # Tidak memisahkan kolom target jika tidak ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifikasi kolom untuk setiap jenis encoding\n",
    "numeric_cols = train_numeric_cols\n",
    "ordinal_encoding_cols = train_ordinal_encoding_cols\n",
    "one_hot_encoding_cols = train_one_hot_encoding_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irisan pada kedua dataset\n",
    "ordinal_encoding_cols = list(set(ordinal_encoding_cols) & set(X_train.columns) & set(X_test.columns))\n",
    "one_hot_encoding_cols = list(set(one_hot_encoding_cols) & set(X_train.columns) & set(X_test.columns))\n",
    "numeric_cols = list(set(numeric_cols) & set(X_train.columns) & set(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan pipeline untuk setiap tipe fitur\n",
    "numerical_pipeline = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore', sparse_output = False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarisasi fitur numerik dan one-hot encoding fitur kategorikal\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown = 'ignore', sparse_output = False)\n",
    "ordinal_transformer = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "\n",
    "preprocessor_stage2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numeric_cols), \n",
    "        (\"cat\", categorical_transformer, one_hot_encoding_cols), \n",
    "        (\"ord\", ordinal_transformer, ordinal_encoding_cols)\n",
    "    ], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat pipeline yang menggabungkan preprocessing dengan model\n",
    "model_pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', preprocessor_stage2),\n",
    "    ('regressor', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan parameter grid untuk GridSearchCV dengan beberapa model\n",
    "param_grid = [\n",
    "    {'regressor': [LinearRegression()]},\n",
    "    {\n",
    "        'regressor': [Ridge()],\n",
    "        'regressor__alpha': [0.1, 1.0, 100.0, 1000.0, 10000.0], \n",
    "        'regressor__max_iter': [50000, 100000, 200000], \n",
    "        'regressor__tol': [1e-3, 1e-4, 1e-6] \n",
    "    },\n",
    "    {\n",
    "        'regressor': [Lasso()],\n",
    "        'regressor__alpha': [0.1, 1.0, 100.0, 1000.0, 10000.0],\n",
    "        'regressor__max_iter': [50000, 100000, 200000],\n",
    "        'regressor__tol': [1e-3, 1e-4, 1e-6]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mengonversi semua kolom dalam X_train ke numerik, mengubah nilai yang tidak dapat dikonversi menjadi NaN\n",
    "# X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Mengecek jumlah nilai NaN dan inf di X_train dan y_train\n",
    "print(\"Jumlah NaN di X_train:\", pd.isna(X_train).sum().sum())\n",
    "print(\"Jumlah inf di X_train:\", np.isinf(X_train).sum().sum())\n",
    "print(\"Jumlah NaN di y_train:\", pd.isna(y_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan Grid Search\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv = 5, scoring = 'neg_mean_squared_error', error_score = np.nan, verbose = 1)\n",
    "\n",
    "# Memeriksa apakah y_train tidak None dan ukuran X_train sesuai\n",
    "if y_train is not None and X_train.shape[0] == y_train.shape[0]:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Ukuran X_train dan y_train tidak cocok atau y_train tidak tersedia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model terbaik dari Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prediksi harga rumah pada data testing menggunakan model terbaik\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan prediksi\n",
    "print(\"Predicted prices:\", y_pred)\n",
    "print(f'Best parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menghitung error (Mean Squared Error) -> membutuhkan niai sebenrnya pada y_test\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f'Mean Squared Error: {mse}')\n",
    "# print(f'Best parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualisasi: Scatter plot dari nilai aktual vs prediksi\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "# plt.title(\"Actual vs Predicted Prices\")\n",
    "# plt.xlabel(\"Actual Prices\")\n",
    "# plt.ylabel(\"Predicted Prices\")\n",
    "# plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
